{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f922c2-a7e2-4461-a359-29b83c514aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c38e24-733d-492e-b10f-faeccb63429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea2d327-79c8-46d8-9510-4431fe8e98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directories():\n",
    "    '''\n",
    "    Creates directories for storing data during a model training run\n",
    "    '''    \n",
    "    # Get current date for saving folder\n",
    "    date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "    # Initialise the run and dir_check to create a new run folder within the current date\n",
    "    run = 0\n",
    "    dir_check = True\n",
    "    # Initialise all pahts\n",
    "    train_path, model_path, save_path, script_path, run_path = None, None, None, None, None\n",
    "    # Find the current run: the first run that doesn't exist yet\n",
    "    while dir_check:\n",
    "        # Construct new paths\n",
    "        run_path    = f'./Summaries/{date}/run{run}/'\n",
    "        train_path  = os.path.join(run_path, 'train')\n",
    "        model_path  = os.path.join(run_path, 'model')\n",
    "        save_path   = os.path.join(run_path, 'save')\n",
    "        script_path = os.path.join(run_path, 'script')\n",
    "        envs_path   = os.path.join(script_path, 'envs')\n",
    "        run += 1\n",
    "\n",
    "        # And once a path doesn't exist yet: create new folders\n",
    "        if not os.path.exists(train_path) and not os.path.exists(model_path) and not os.path.exists(save_path):\n",
    "            os.makedirs(train_path)\n",
    "            os.makedirs(model_path)\n",
    "            os.makedirs(save_path)\n",
    "            os.makedirs(script_path)\n",
    "            os.makedirs(envs_path)\n",
    "            dir_check = False\n",
    "    # Return folders to new path\n",
    "    return run_path, train_path, model_path, save_path, script_path, envs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b0a0ce-2b08-4a22-aaef-683f77d515bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training from step 0\n",
    "i_start = 0\n",
    "\n",
    "# Create directories for storing all information about the current run\n",
    "run_path, train_path, model_path, save_path, script_path, envs_path = make_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d817a755-14af-4c3e-98dc-f0175c634d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying file='./hello.py' to dst='./Summaries/2025-05-19/run0/script/./hello.py'\n"
     ]
    }
   ],
   "source": [
    "# Save all python files in current directory to script directory\n",
    "files = glob.iglob(os.path.join('.', '*.py'))\n",
    "for file in files:\n",
    "    if os.path.isfile(file):\n",
    "        dst = os.path.join(script_path, file)\n",
    "        print(f'copying {file=} to {dst=}')\n",
    "        shutil.copy2(file, dst) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f190d64-2aee-41a7-84d1-a16d86ddec4c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fcdfbc7-ac1e-4797-a35b-8b1d5cd45d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying file='./envs/5x5.json' to dst='./Summaries/2025-05-19/run0/script/envs/5x5.json'\n"
     ]
    }
   ],
   "source": [
    "# Create list of environments that we will sample from during training to provide TEM with trajectory input\n",
    "envs = ['./envs/5x5.json']\n",
    "# Save all environment files that are being used in training in the script directory\n",
    "for file in set(envs):\n",
    "    dst = os.path.join(envs_path, os.path.basename(file))\n",
    "    print(f'copying {file=} to {dst=}')\n",
    "    shutil.copy2(file, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ab4d296-c1d0-4c65-aedf-776fc9593565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbf06074-670c-466c-ba20-a665b19e3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./envs/5x5.json', 'r') as f:\n",
    "    _data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d6214fd-2d73-44d0-8660-547e13fbf77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['n_locations', 'n_observations', 'n_actions', 'adjacency', 'locations'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27e4813f-ea8d-4bfa-8a4a-9706a4ce0742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 45, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data['n_locations'], _data['n_observations'], _data['n_actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62a150eb-68e5-435b-a29b-01eecd551e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 25,\n",
       " [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_data['adjacency']), len(_data['adjacency']), _data['adjacency'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41de9bb9-480e-43ae-a722-acbc215dd8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 25)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_data['locations']), len(_data['locations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e80217e0-4e84-4483-845b-705cc2a1c996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              -> 0\n",
      "observation     -> 31\n",
      "x               -> 0.1\n",
      "y               -> 0.1\n",
      "in_locations    -> [0, 1, 5]\n",
      "in_degree       -> 3\n",
      "out_locations   -> [0, 1, 5]\n",
      "out_degree      -> 3\n",
      "actions ->\n",
      "  {'id': 0, 'transition': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 1, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n",
      "  {'id': 2, 'transition': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 3, 'transition': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 4, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, v in _data['locations'][0].items():\n",
    "    if k != 'actions':\n",
    "        print(f'{k:<15} -> {v}')\n",
    "    else:\n",
    "        print(f'{k} ->')\n",
    "        for action in v:\n",
    "            print(f'  {action}')\n",
    "\n",
    "len(_data['locations'][0]['actions'][0]['transition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c4e032b-bfb5-415f-bdbf-3cf1d8ae9b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where( np.array(_data['locations'][0]['actions'][0]['transition']) > 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac9f9a6a-f987-4121-923d-83d6d884f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where( np.array(_data['locations'][0]['actions'][1]['transition']) > 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b7798d6-d56b-49a6-945a-efdae2695118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['./envs/5x5.json', './envs/5x5.json', './envs/5x5.json'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs = ['./envs/5x5.json']\n",
    "\n",
    "np.random.choice(envs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b76ba60e-7776-4958-9ff0-9992cde4fe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0, 1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3f2590c-b4c8-44b2-893d-8a5159178897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done in\n",
    "# https://github.com/jbakermans/torch_tem/blob/bf103fb32b5fdc7541ebbd95ba77a2d35d049d7c/world.py#L56\n",
    "# TEM needs to know that this is a non-shiny environment (e.g. for providing actions to\n",
    "# generative model), so set shiny to None for each location.\n",
    "for location in _data['locations']:\n",
    "    location['shiny'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ead8013d-5478-4446-b4ed-a06ee1cc0319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              -> 0\n",
      "observation     -> 31\n",
      "x               -> 0.1\n",
      "y               -> 0.1\n",
      "in_locations    -> [0, 1, 5]\n",
      "in_degree       -> 3\n",
      "out_locations   -> [0, 1, 5]\n",
      "out_degree      -> 3\n",
      "actions ->\n",
      "  {'id': 0, 'transition': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 1, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n",
      "  {'id': 2, 'transition': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 3, 'transition': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 4, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n",
      "shiny           -> None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, v in _data['locations'][0].items():\n",
    "    if k != 'actions':\n",
    "        print(f'{k:<15} -> {v}')\n",
    "    else:\n",
    "        print(f'{k} ->')\n",
    "        for action in v:\n",
    "            print(f'  {action}')\n",
    "\n",
    "len(_data['locations'][0]['actions'][0]['transition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a8d7426d-d965-4c2c-869a-63e047ed07e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environments = [_data]\n",
    "\n",
    "# Initialise whether a state has been visited for each world\n",
    "visited = [ [ False for _ in range(env['n_locations']) ] for env in environments]\n",
    "len(visited), len(visited[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6a5a3-4375-4880-8adc-aaa98307ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(env, walk):\n",
    "    # First step: start at random location\n",
    "    if len(walk) == 0:\n",
    "        new_location = np.random.randint(env['n_locations'])\n",
    "    # Any other step: get new location from previous location and action\n",
    "    else:                        \n",
    "        new_location = int(\n",
    "            np.flatnonzero(\n",
    "                np.cumsum(\n",
    "                    walk[-1][0]['actions'][walk[-1][2]]['transition'],\n",
    "                )>np.random.rand(),\n",
    "            )[0]\n",
    "        )\n",
    "    # Return the location dictionary of the new location\n",
    "    return env['locations'][new_location]\n",
    "\n",
    "def get_observation(env, new_location):\n",
    "        # Find sensory observation for new state, and store it as one-hot vector\n",
    "        new_observation = np.eye(env['n_observations'])[new_location['observation']]\n",
    "        # Create a new observation by converting the new observation to a torch tensor\n",
    "        new_observation = torch.tensor(new_observation, dtype=torch.float).view((new_observation.shape[0]))\n",
    "        # Return the new observation\n",
    "        return new_observation\n",
    "\n",
    "def get_action(env, new_location, walk, repeat_bias_factor=2):\n",
    "        # Build policy from action probability of each action of provided location dictionary\n",
    "        policy = np.array([action['probability'] for action in new_location['actions']])        \n",
    "        # Add a bias for repeating previous action to walk in straight lines, only if (this is not the first step) and (the previous action was a move)\n",
    "        policy[[] if len(walk) == 0 or new_location['id'] == walk[-1][0]['id'] else walk[-1][2]] *= repeat_bias_factor\n",
    "        # And renormalise policy (note that for unavailable actions, the policy was 0 and remains 0, so in that case no renormalisation needed)\n",
    "        policy = policy / sum(policy) if sum(policy) > 0 else policy\n",
    "        # Select action in new state\n",
    "        new_action = int(np.flatnonzero(np.cumsum(policy)>np.random.rand())[0])\n",
    "        # Return the new action\n",
    "        return new_action\n",
    "\n",
    "def walk_default(env, walk, walk_length, repeat_bias_factor=2):\n",
    "    # Finish the provided walk until it contains walk_length steps\n",
    "    for curr_step in range(walk_length - len(walk)):\n",
    "        # Get new location based on previous action and location\n",
    "        new_location = get_location(env, walk)\n",
    "        # Get new observation at new location\n",
    "        new_observation = get_observation(env, new_location)\n",
    "        # Get new action based on policy at new location\n",
    "        new_action = get_action(env, new_location, walk)\n",
    "        # Append location, observation, and action to the walk\n",
    "        walk.append([new_location, new_observation, new_action])\n",
    "    # Return the final walk\n",
    "    return walk\n",
    "\n",
    "def generate_walks(env, walk_length=10, n_walk=100, repeat_bias_factor=2, shiny=False):\n",
    "    # Generate walk by sampling actions accoring to policy, then next state according to graph\n",
    "    walks = [] # This is going to contain a list of (state, observation, action) tuples\n",
    "    for currWalk in range(n_walk):\n",
    "        new_walk = []\n",
    "        # If shiny hasn't been specified: there are no shiny objects, generate default policy\n",
    "        if shiny is None:\n",
    "            new_walk = walk_default(env, new_walk, walk_length, repeat_bias_factor)\n",
    "        ## If shiny was specified: use policy that uses shiny policy to approach shiny objects\n",
    "        ## sequentially\n",
    "        ##else:\n",
    "        ##    new_walk = self.walk_shiny(new_walk, walk_length, repeat_bias_factor)\n",
    "        # Clean up walk a bit by only keep essential location dictionary entries\n",
    "        for step in new_walk[:-1]:\n",
    "            step[0] = {'id': step[0]['id'], 'shiny': step[0]['shiny']}\n",
    "        # Append new walk to list of walks\n",
    "        walks.append(new_walk)   \n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ace6a4-2897-4a1b-89f3-15cb2e86ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And make a single walk for each environment, where walk lengths can be any between the min and max\n",
    "# length to de-sychronise world switches\n",
    "walks = [\n",
    "    env.generate_walks(\n",
    "        params['n_rollout']*np.random.randint(params['walk_it_min'], params['walk_it_max']),\n",
    "        1,\n",
    "    )[0] for env in environments\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc91c5-78ed-4413-bf52-17c70b27d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward-pass this walk through the network\n",
    "# forward = tem(chunk, prev_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1413f-0c80-4975-86bc-93aba6a8206a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdb1fc-746b-412c-bf38-a5fb8277065b",
   "metadata": {},
   "source": [
    "The TEM model is based on the architecture described in the paper, where there are representations for:\n",
    "\n",
    "* Abstract location (`g`) - corresponding to grid cells in medial entorhinal cortex\n",
    "* Grounded location (`p`) - corresponding to place cells in hippocampus\n",
    "* Sensory observations (`x`) - corresponding to lateral entorhinal cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8adb218f-4586-423b-8506-fd0ae458753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters():\n",
    "    params = {}\n",
    "    # -- Model parameters   \n",
    "    # Decide whether to use seperate grid modules that recieve shiny information for object vector cells.\n",
    "    # To disable OVC, set this False, and set n_ovc to [0 for _ in range(len(params['n_g_subsampled']))].\n",
    "    params['separate_ovc'] = False\n",
    "\n",
    "    # ---- Neuron and module parameters\n",
    "    # Neurons for subsampled entorhinal abstract location f_g(g) for each frequency module\n",
    "    params['n_g_subsampled'] = [10, 10, 8, 6, 6]\n",
    "    # Neurons for object vector cells. Neurons will get new modules if object vector cell modules\n",
    "    # are separated; otherwise, they are added to existing abstract location modules.\n",
    "    # a) No additional modules, no additional object vector neurons (e.g. when not using shiny\n",
    "    #    environments): [0 for _ in range(len(params['n_g_subsampled']))], and separate_ovc set to False\n",
    "    # b) No additional modules, but n additional object vector neurons in each grid module:\n",
    "    #    [n for _ in range(len(params['n_g_subsampled']))], and separate_ovc set to False\n",
    "    # c) Additional separate object vector modules, with n, m neurons: [n, m], and separate_ovc set to\n",
    "    #    True\n",
    "    params['n_ovc'] = [0 for _ in range(len(params['n_g_subsampled']))]\n",
    "    # Total number of modules\n",
    "    params['n_f'] = len(params['n_g_subsampled'])\n",
    "\n",
    "    # Number of hierarchical frequency modules for object vector cells\n",
    "    params['n_f_ovc'] = len(params['n_ovc']) if params['separate_ovc'] else 0\n",
    "\n",
    "    # Initial frequencies of each module. For ease of interpretation (higher number = higher frequency)\n",
    "    # this is 1 - the frequency as James uses it\n",
    "    params['f_initial'] = [0.99, 0.3, 0.09, 0.03, 0.01]\n",
    "    # Add frequencies of object vector cell modules, if object vector cells get separate modules\n",
    "    params['f_initial'] = params['f_initial'] + params['f_initial'][0:params['n_f_ovc']]\n",
    "    return params\n",
    "\n",
    "# Initalise hyperparameters for model\n",
    "params = parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "284c72d7-9c33-4be5-ac6d-3a96a31594ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'separate_ovc': False,\n",
       " 'n_g_subsampled': [10, 10, 8, 6, 6],\n",
       " 'n_ovc': [0, 0, 0, 0, 0],\n",
       " 'n_f': 5,\n",
       " 'n_f_ovc': 0,\n",
       " 'f_initial': [0.99, 0.3, 0.09, 0.03, 0.01]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0258fe30-6016-4a4d-8d5a-304b3a43e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters\n",
    "np.save(os.path.join(save_path, 'params'), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4424e70f-9448-4b26-9df3-7def8f566c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9b3f4c4-e34f-41bb-b8ce-6e0af36d4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale factor in Laplacian transform for each frequency module. High frequency comes first, low frequency comes last. Learn inverse sigmoid instead of scale factor directly, so domain of alpha is -inf, inf\n",
    "alpha = torch.nn.ParameterList(\n",
    "    [\n",
    "        torch.nn.Parameter(\n",
    "            torch.tensor(\n",
    "                np.log(hyper['f_initial'][f] / (1 - hyper['f_initial'][f])),\n",
    "                dtype=torch.float,\n",
    "            )\n",
    "        ) for f in range(hyper['n_f'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ab4cf71-ae73-42c9-85e1-92f558de2ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.float32 of size ]\n",
       "    (1): Parameter containing: [torch.float32 of size ]\n",
       "    (2): Parameter containing: [torch.float32 of size ]\n",
       "    (3): Parameter containing: [torch.float32 of size ]\n",
       "    (4): Parameter containing: [torch.float32 of size ]\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d3306-d7a4-4160-9fc6-5de0acc438f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
