{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386cd910-4825-4220-9abd-c0efbaaef839",
   "metadata": {},
   "source": [
    "# Environment JSON Schema Documentation\n",
    "\n",
    "## Overview\n",
    "\n",
    "The environment JSON defines a **graph-based spatial world** where an agent can navigate between locations. Each location has sensory observations and possible actions that lead to other locations with specified probabilities.\n",
    "\n",
    "## Top-Level Structure\n",
    "\n",
    "```json\n",
    "{\n",
    " \"n_locations\": 25,           // Total number of locations in the environment\n",
    " \"n_observations\": 45,        // Total number of unique observations available\n",
    " \"n_actions\": 5,              // Total number of possible action types\n",
    " \"adjacency\": [[...], ...],   // 2D adjacency matrix (n_locations × n_locations)\n",
    " \"locations\": [...]           // Array of location objects\n",
    "}\n",
    "```\n",
    "\n",
    "The adjacency matrix shows direct connections between locations in the grid.\n",
    "For the first row `[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]`:\n",
    "\n",
    "- Position 0: 1 → Location 0 connects to itself (can stay put)\n",
    "- Position 1: 1 → Location 0 connects to Location 1 (can move east)\n",
    "- Position 5: 1 → Location 0 connects to Location 5 (can move south)\n",
    "- All others: 0 → No direct connection\n",
    "\n",
    "So Location 0 (top-left corner at coordinates 0.1,0.1) can only reach:\n",
    "\n",
    "Itself (stay)\n",
    "Location 1 (move right)\n",
    "Location 5 (move down)\n",
    "\n",
    "This makes sense for a corner position - you can't go north or west from the top-left corner of the grid.\n",
    "The adjacency matrix is essentially a compact representation of which locations are neighbors in the spatial grid.\n",
    "\n",
    "---\n",
    "# Location Object Schema\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": 3,                    // Unique location identifier (0 to n_locations-1)\n",
    "  \"observation\": 33,          // Observation ID seen at this location (0 to n_observations-1)\n",
    "  \"x\": 0.7,                   // X coordinate in normalized space\n",
    "  \"y\": 0.1,                   // Y coordinate in normalized space\n",
    "  \"in_locations\": [2,3,4,8],  // List of location IDs that can reach this location\n",
    "  \"in_degree\": 4,             // Number of incoming connections (length of in_locations)\n",
    "  \"out_locations\": [2,3,4,8], // List of location IDs reachable from this location\n",
    "  \"out_degree\": 4,            // Number of outgoing connections (length of out_locations)\n",
    "  \"shiny\": null,              // Whether location contains shiny objects (null/true/false)\n",
    "  \"actions\": [...]            // Array of possible actions from this location\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "# Action Object Schema\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": 0,                     // Action identifier (0 to n_actions-1)\n",
    "  \"transition\": [0,0,0,1,0...], // Probability distribution over next locations\n",
    "  \"probability\": 0.25          // Probability of selecting this action\n",
    "}\n",
    "```\n",
    "\n",
    "## Action Types by ID\n",
    "\n",
    "- 0: Stay in place / No movement\n",
    "- 1: Move North (typically probability 0 if impossible)\n",
    "- 2: Move East\n",
    "- 3: Move South\n",
    "- 4: Move West\n",
    "\n",
    "\n",
    "## Key Concepts\n",
    "### Transition Vector\n",
    "\n",
    "The transition array is a probability distribution over all locations:\n",
    "\n",
    "Length = n_locations (25 in the example)\n",
    "Each index corresponds to a location ID\n",
    "Value at index i = probability of transitioning to location i\n",
    "Deterministic transitions: exactly one 1.0, rest are 0.0\n",
    "Stochastic transitions: multiple non-zero values that sum to 1.0\n",
    "\n",
    "### Observation Encoding\n",
    "Observations are encoded as one-hot vectors:\n",
    "\n",
    "Vector length = n_observations (45 in the example)\n",
    "If observation: 33, then position 33 = 1.0, all others = 0.0\n",
    "\n",
    "---\n",
    "\n",
    "# Example Walkthrough\n",
    "\n",
    "Location 3 Analysis\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": 3,\n",
    "  \"observation\": 33,\n",
    "  \"x\": 0.7, \"y\": 0.1,\n",
    "  \"in_locations\": [2,3,4,8],\n",
    "  \"out_locations\": [2,3,4,8],\n",
    "  \"actions\": [\n",
    "    {\"id\": 0, \"transition\": [0,0,0,1,0,...], \"probability\": 0.25},  // Stay at location 3\n",
    "    {\"id\": 1, \"transition\": [0,0,0,0,0,...], \"probability\": 0.0},   // North (impossible)\n",
    "    {\"id\": 2, \"transition\": [0,0,0,0,1,...], \"probability\": 0.25},  // East to location 4\n",
    "    {\"id\": 3, \"transition\": [0,0,0,0,0,0,0,0,1,...], \"probability\": 0.25}, // South to location 8\n",
    "    {\"id\": 4, \"transition\": [0,0,1,0,0,...], \"probability\": 0.25}   // West to location 2\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- Agent at coordinates (0.7, 0.1) - fourth column, top row of 5×5 grid\n",
    "- Sees landmark/object #33\n",
    "- Can move to 4 different locations (including staying put)\n",
    "- Cannot move North (action 1 has probability 0 - already at top edge)\n",
    "- All other moves equally likely (25% each)\n",
    "\n",
    "Grid Layout Context\n",
    "\n",
    "In a 5×5 grid with coordinates starting at (0.1, 0.1) and incrementing by 0.2:\n",
    "\n",
    "```\n",
    "(0.1,0.1) - (0.3,0.1) - (0.5,0.1) - (0.7,0.1) - (0.9,0.1)\n",
    "    |           |           |           |           |\n",
    "(0.1,0.3) - (0.3,0.3) - (0.5,0.3) - (0.7,0.3) - (0.9,0.3)\n",
    "    |           |           |           |           |\n",
    "(0.1,0.5) - (0.3,0.5) - (0.5,0.5) - (0.7,0.5) - (0.9,0.5)\n",
    "    |           |           |           |           |\n",
    "(0.1,0.7) - (0.3,0.7) - (0.5,0.7) - (0.7,0.7) - (0.9,0.7)\n",
    "    |           |           |           |           |\n",
    "(0.1,0.9) - (0.3,0.9) - (0.5,0.9) - (0.7,0.9) - (0.9,0.9)\n",
    "```\n",
    "\n",
    "Location 3 at (0.7, 0.1) is in the top row, fourth position (0-indexed: positions 0,1,2,3,4).\n",
    "\n",
    "The TEM model uses this data to:\n",
    "\n",
    "1. Generate walks: Sample sequences of (location, observation, action) tuples\n",
    "1. Learn structure: Infer spatial relationships from observation sequences\n",
    "1. Predict observations: Given a sequence, predict what comes next\n",
    "\n",
    "The model never sees the explicit coordinates, adjacency matrix, or transition probabilities - it must learn the environment's structure purely from the sequence of observations and actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f922c2-a7e2-4461-a359-29b83c514aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c38e24-733d-492e-b10f-faeccb63429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea2d327-79c8-46d8-9510-4431fe8e98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directories():\n",
    "    '''\n",
    "    Creates directories for storing data during a model training run\n",
    "    '''    \n",
    "    # Get current date for saving folder\n",
    "    date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "    # Initialise the run and dir_check to create a new run folder within the current date\n",
    "    run = 0\n",
    "    dir_check = True\n",
    "    # Initialise all pahts\n",
    "    train_path, model_path, save_path, script_path, run_path = None, None, None, None, None\n",
    "    # Find the current run: the first run that doesn't exist yet\n",
    "    while dir_check:\n",
    "        # Construct new paths\n",
    "        run_path    = f'./Summaries/{date}/run{run}/'\n",
    "        train_path  = os.path.join(run_path, 'train')\n",
    "        model_path  = os.path.join(run_path, 'model')\n",
    "        save_path   = os.path.join(run_path, 'save')\n",
    "        script_path = os.path.join(run_path, 'script')\n",
    "        envs_path   = os.path.join(script_path, 'envs')\n",
    "        run += 1\n",
    "\n",
    "        # And once a path doesn't exist yet: create new folders\n",
    "        if not os.path.exists(train_path) and not os.path.exists(model_path) and not os.path.exists(save_path):\n",
    "            os.makedirs(train_path)\n",
    "            os.makedirs(model_path)\n",
    "            os.makedirs(save_path)\n",
    "            os.makedirs(script_path)\n",
    "            os.makedirs(envs_path)\n",
    "            dir_check = False\n",
    "    # Return folders to new path\n",
    "    return run_path, train_path, model_path, save_path, script_path, envs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b0a0ce-2b08-4a22-aaef-683f77d515bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training from step 0\n",
    "i_start = 0\n",
    "\n",
    "# Create directories for storing all information about the current run\n",
    "run_path, train_path, model_path, save_path, script_path, envs_path = make_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d817a755-14af-4c3e-98dc-f0175c634d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying file='./hello.py' to dst='./Summaries/2025-05-27/run0/script/./hello.py'\n"
     ]
    }
   ],
   "source": [
    "# Save all python files in current directory to script directory\n",
    "files = glob.iglob(os.path.join('.', '*.py'))\n",
    "for file in files:\n",
    "    if os.path.isfile(file):\n",
    "        dst = os.path.join(script_path, file)\n",
    "        print(f'copying {file=} to {dst=}')\n",
    "        shutil.copy2(file, dst) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f190d64-2aee-41a7-84d1-a16d86ddec4c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fcdfbc7-ac1e-4797-a35b-8b1d5cd45d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying file='./envs/5x5.json' to dst='./Summaries/2025-05-27/run0/script/envs/5x5.json'\n"
     ]
    }
   ],
   "source": [
    "# Create list of environments that we will sample from during training to provide TEM with trajectory input\n",
    "envs = ['./envs/5x5.json']\n",
    "# Save all environment files that are being used in training in the script directory\n",
    "for file in set(envs):\n",
    "    dst = os.path.join(envs_path, os.path.basename(file))\n",
    "    print(f'copying {file=} to {dst=}')\n",
    "    shutil.copy2(file, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab4d296-c1d0-4c65-aedf-776fc9593565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf06074-670c-466c-ba20-a665b19e3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./envs/5x5.json', 'r') as f:\n",
    "    _data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d6214fd-2d73-44d0-8660-547e13fbf77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['n_locations', 'n_observations', 'n_actions', 'adjacency', 'locations'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e4813f-ea8d-4bfa-8a4a-9706a4ce0742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 45, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data['n_locations'], _data['n_observations'], _data['n_actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62a150eb-68e5-435b-a29b-01eecd551e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 25,\n",
       " [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_data['adjacency']), len(_data['adjacency']), _data['adjacency'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41de9bb9-480e-43ae-a722-acbc215dd8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_data['locations']), len(_data['locations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80217e0-4e84-4483-845b-705cc2a1c996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              -> 0\n",
      "observation     -> 31\n",
      "x               -> 0.1\n",
      "y               -> 0.1\n",
      "in_locations    -> [0, 1, 5]\n",
      "in_degree       -> 3\n",
      "out_locations   -> [0, 1, 5]\n",
      "out_degree      -> 3\n",
      "actions ->\n",
      "  {'id': 0, 'transition': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 1, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n",
      "  {'id': 2, 'transition': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 3, 'transition': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 4, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, v in _data['locations'][0].items():\n",
    "    if k != 'actions':\n",
    "        print(f'{k:<15} -> {v}')\n",
    "    else:\n",
    "        print(f'{k} ->')\n",
    "        for action in v:\n",
    "            print(f'  {action}')\n",
    "\n",
    "len(_data['locations'][0]['actions'][0]['transition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c4e032b-bfb5-415f-bdbf-3cf1d8ae9b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where( np.array(_data['locations'][0]['actions'][0]['transition']) > 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac9f9a6a-f987-4121-923d-83d6d884f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where( np.array(_data['locations'][0]['actions'][1]['transition']) > 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b7798d6-d56b-49a6-945a-efdae2695118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['./envs/5x5.json', './envs/5x5.json', './envs/5x5.json'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs = ['./envs/5x5.json']\n",
    "\n",
    "np.random.choice(envs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b76ba60e-7776-4958-9ff0-9992cde4fe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0, 1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f2590c-b4c8-44b2-893d-8a5159178897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is done in\n",
    "# https://github.com/jbakermans/torch_tem/blob/bf103fb32b5fdc7541ebbd95ba77a2d35d049d7c/world.py#L56\n",
    "# TEM needs to know that this is a non-shiny environment (e.g. for providing actions to\n",
    "# generative model), so set shiny to None for each location.\n",
    "for location in _data['locations']:\n",
    "    location['shiny'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ead8013d-5478-4446-b4ed-a06ee1cc0319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              -> 0\n",
      "observation     -> 31\n",
      "x               -> 0.1\n",
      "y               -> 0.1\n",
      "in_locations    -> [0, 1, 5]\n",
      "in_degree       -> 3\n",
      "out_locations   -> [0, 1, 5]\n",
      "out_degree      -> 3\n",
      "actions ->\n",
      "  {'id': 0, 'transition': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 1, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n",
      "  {'id': 2, 'transition': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 3, 'transition': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.3333333333333333}\n",
      "  {'id': 4, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n",
      "shiny           -> None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, v in _data['locations'][0].items():\n",
    "    if k != 'actions':\n",
    "        print(f'{k:<15} -> {v}')\n",
    "    else:\n",
    "        print(f'{k} ->')\n",
    "        for action in v:\n",
    "            print(f'  {action}')\n",
    "\n",
    "len(_data['locations'][0]['actions'][0]['transition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8d7426d-d965-4c2c-869a-63e047ed07e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environments = [_data]\n",
    "\n",
    "# Initialise whether a state has been visited for each world\n",
    "visited = [ [ False for _ in range(env['n_locations']) ] for env in environments]\n",
    "len(visited), len(visited[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ae1fde0-1f53-4d29-9361-f7ffa7aa2717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: 3\n",
      "---> step 2: \n",
      "\t_env['locations'][_new_location]={'id': 3, 'observation': 33, 'x': 0.7, 'y': 0.1, 'in_locations': [2, 3, 4, 8], 'in_degree': 4, 'out_locations': [2, 3, 4, 8], 'out_degree': 4, 'actions': [{'id': 0, 'transition': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.25}, {'id': 1, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}, {'id': 2, 'transition': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.25}, {'id': 3, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.25}, {'id': 4, 'transition': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.25}], 'shiny': None}\n",
      "step 2: \n",
      "\tdict_keys(['id', 'observation', 'x', 'y', 'in_locations', 'in_degree', 'out_locations', 'out_degree', 'actions', 'shiny'])\n",
      "\n",
      "step 3: _new_location[\"observation\"]=33\n",
      "---> step 3: _new_observation=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "step 3: _new_observation=tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "step 4: action={'id': 0, 'transition': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.25}\n",
      "step 4: action={'id': 1, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0}\n",
      "step 4: action={'id': 2, 'transition': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.25}\n",
      "step 4: action={'id': 3, 'transition': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.25}\n",
      "step 4: action={'id': 4, 'transition': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'probability': 0.25}\n",
      "step 4: _policy=array([0.25, 0.  , 0.25, 0.25, 0.25])\n"
     ]
    }
   ],
   "source": [
    "_env = environments[0]\n",
    "\n",
    "_new_location = np.random.randint(25)\n",
    "print(f'step 1: {_new_location}')\n",
    "\n",
    "_env['locations'][_new_location]\n",
    "print(f'---> step 2: \\n\\t{_env['locations'][_new_location]=}')\n",
    "print(f'step 2: \\n\\t{_env['locations'][_new_location].keys()}')\n",
    "print()\n",
    "\n",
    "_new_location = _env['locations'][_new_location]\n",
    "_new_observation = np.eye(_env['n_observations'])[_new_location['observation']]\n",
    "print(f'step 3: {_new_location[\"observation\"]=}')\n",
    "print(f'---> step 3: {_new_observation=}')\n",
    "_new_observation = torch.tensor(_new_observation, dtype=torch.float).view((_new_observation.shape[0]))\n",
    "print(f'step 3: {_new_observation=}')\n",
    "print()\n",
    "\n",
    "_policy = np.array([action['probability'] for action in _new_location['actions']])\n",
    "for action in _new_location['actions']:\n",
    "    print(f'step 4: {action=}')\n",
    "print(f'step 4: {_policy=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae39afb1-3110-420e-9453-368de43115a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_new_location['id']=20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{_new_location['id']=}\")\n",
    "_walk = []\n",
    "\n",
    "[[] if len(_walk) == 0 or new_location['id'] == _walk[-1][0]['id'] else _walk[-1][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e310303-20a0-4176-8e25-77ed81998e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# funky way of saying \"give me the entries with these indices\"\n",
    "_policy[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80e2ee01-005e-43b0-be4f-4988e090069c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.        ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_policy[[0, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3097ec9-7974-434a-a19a-8b20d4e37e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333, 0.        , 0.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_repeat_bias_factor = 1\n",
    "\n",
    "# Add a bias for repeating previous action to walk in straight lines,\n",
    "# only if (this is not the first step) and (the previous action was a move)\n",
    "_policy[[] if len(_walk) == 0 or new_location['id'] == _walk[-1][0]['id'] else _walk[-1][2]] *= _repeat_bias_factor\n",
    "\n",
    "_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "016dc8c4-28ce-4088-9aef-1435e52704bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333, 0.        , 0.        ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_policy = _policy / sum(_policy)\n",
    "_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99dc3592-4eda-43a6-b0eb-97bb55a3c88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_a_rand=0.01538814652392606\n",
      "[ True  True  True  True  True]\n",
      "[0 1 2 3 4]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "_a_rand = np.random.rand()\n",
    "print(f'{_a_rand=}')\n",
    "print( np.cumsum(_policy)>_a_rand )\n",
    "print( np.flatnonzero(np.cumsum(_policy)>_a_rand) )\n",
    "_new_action = int(np.flatnonzero(np.cumsum(_policy)>_a_rand)[0])\n",
    "print(_new_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee58c01f-c094-4bf1-814d-d67e25e39665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 3,\n",
       "  'observation': 33,\n",
       "  'x': 0.7,\n",
       "  'y': 0.1,\n",
       "  'in_locations': [2, 3, 4, 8],\n",
       "  'in_degree': 4,\n",
       "  'out_locations': [2, 3, 4, 8],\n",
       "  'out_degree': 4,\n",
       "  'actions': [{'id': 0,\n",
       "    'transition': [0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0],\n",
       "    'probability': 0.25},\n",
       "   {'id': 1,\n",
       "    'transition': [0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0],\n",
       "    'probability': 0},\n",
       "   {'id': 2,\n",
       "    'transition': [0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0],\n",
       "    'probability': 0.25},\n",
       "   {'id': 3,\n",
       "    'transition': [0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0],\n",
       "    'probability': 0.25},\n",
       "   {'id': 4,\n",
       "    'transition': [0,\n",
       "     0,\n",
       "     1,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0],\n",
       "    'probability': 0.25}],\n",
       "  'shiny': None},\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_new_location, _new_observation, _new_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb4fcfeb-8f35-456e-ae07-31a99ab18765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc=0   id=0   observation=31  x=0.1 y=0.1\n",
      "loc=1   id=1   observation=39  x=0.3 y=0.1\n",
      "loc=2   id=2   observation=21  x=0.5 y=0.1\n",
      "loc=3   id=3   observation=33  x=0.7 y=0.1\n",
      "loc=4   id=4   observation=34  x=0.9 y=0.1\n",
      "loc=5   id=5   observation=5   x=0.1 y=0.3\n",
      "loc=6   id=6   observation=2   x=0.3 y=0.3\n",
      "loc=7   id=7   observation=15  x=0.5 y=0.3\n",
      "loc=8   id=8   observation=10  x=0.7 y=0.3\n",
      "loc=9   id=9   observation=29  x=0.9 y=0.3\n",
      "loc=10  id=10  observation=44  x=0.1 y=0.5\n",
      "loc=11  id=11  observation=32  x=0.3 y=0.5\n",
      "loc=12  id=12  observation=6   x=0.5 y=0.5\n",
      "loc=13  id=13  observation=37  x=0.7 y=0.5\n",
      "loc=14  id=14  observation=41  x=0.9 y=0.5\n",
      "loc=15  id=15  observation=27  x=0.1 y=0.7\n",
      "loc=16  id=16  observation=16  x=0.3 y=0.7\n",
      "loc=17  id=17  observation=40  x=0.5 y=0.7\n",
      "loc=18  id=18  observation=13  x=0.7 y=0.7\n",
      "loc=19  id=19  observation=7   x=0.9 y=0.7\n",
      "loc=20  id=20  observation=4   x=0.1 y=0.9\n",
      "loc=21  id=21  observation=28  x=0.3 y=0.9\n",
      "loc=22  id=22  observation=20  x=0.5 y=0.9\n",
      "loc=23  id=23  observation=24  x=0.7 y=0.9\n",
      "loc=24  id=24  observation=36  x=0.9 y=0.9\n"
     ]
    }
   ],
   "source": [
    "for loc in range(len(_env['locations'])):\n",
    "    print(f\"{loc=:<3} id={_env['locations'][loc]['id']:<3} observation={_env['locations'][loc]['observation']:<3} x={_env['locations'][loc]['x']:<3} y={_env['locations'][loc]['y']:<3}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6a5a3-4375-4880-8adc-aaa98307ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(env, walk):\n",
    "    # First step: start at random location\n",
    "    if len(walk) == 0:\n",
    "        new_location = np.random.randint(env['n_locations'])\n",
    "    # Any other step: get new location from previous location and action\n",
    "    else:                        \n",
    "        new_location = int(\n",
    "            np.flatnonzero(\n",
    "                np.cumsum(\n",
    "                    walk[-1][0]['actions'][walk[-1][2]]['transition'],\n",
    "                )>np.random.rand(),\n",
    "            )[0]\n",
    "        )\n",
    "    # Return the location dictionary of the new location\n",
    "    return env['locations'][new_location]\n",
    "\n",
    "def get_observation(env, new_location):\n",
    "        # Find sensory observation for new state, and store it as one-hot vector\n",
    "        new_observation = np.eye(env['n_observations'])[new_location['observation']]\n",
    "        # Create a new observation by converting the new observation to a torch tensor\n",
    "        new_observation = torch.tensor(new_observation, dtype=torch.float).view((new_observation.shape[0]))\n",
    "        # Return the new observation\n",
    "        return new_observation\n",
    "\n",
    "def get_action(env, new_location, walk, repeat_bias_factor=2):\n",
    "        # Build policy from action probability of each action of provided location dictionary\n",
    "        policy = np.array([action['probability'] for action in new_location['actions']])        \n",
    "        # Add a bias for repeating previous action to walk in straight lines, only if (this is not the first step) and (the previous action was a move)\n",
    "        policy[[] if len(walk) == 0 or new_location['id'] == walk[-1][0]['id'] else walk[-1][2]] *= repeat_bias_factor\n",
    "        # And renormalise policy (note that for unavailable actions, the policy was 0 and remains 0, so in that case no renormalisation needed)\n",
    "        policy = policy / sum(policy) if sum(policy) > 0 else policy\n",
    "        # Select action in new state\n",
    "        new_action = int(np.flatnonzero(np.cumsum(policy)>np.random.rand())[0])\n",
    "        # Return the new action\n",
    "        return new_action\n",
    "\n",
    "def walk_default(env, walk, walk_length, repeat_bias_factor=2):\n",
    "    # Finish the provided walk until it contains walk_length steps\n",
    "    for curr_step in range(walk_length - len(walk)):\n",
    "        # Get new location based on previous action and location\n",
    "        new_location = get_location(env, walk)\n",
    "        # Get new observation at new location\n",
    "        new_observation = get_observation(env, new_location)\n",
    "        # Get new action based on policy at new location\n",
    "        new_action = get_action(env, new_location, walk)\n",
    "        # Append location, observation, and action to the walk\n",
    "        walk.append([new_location, new_observation, new_action])\n",
    "    # Return the final walk\n",
    "    return walk\n",
    "\n",
    "def generate_walks(env, walk_length=10, n_walk=100, repeat_bias_factor=2, shiny=False):\n",
    "    # Generate walk by sampling actions accoring to policy, then next state according to graph\n",
    "    walks = [] # This is going to contain a list of (state, observation, action) tuples\n",
    "    for currWalk in range(n_walk):\n",
    "        new_walk = []\n",
    "        # If shiny hasn't been specified: there are no shiny objects, generate default policy\n",
    "        if shiny is None:\n",
    "            new_walk = walk_default(env, new_walk, walk_length, repeat_bias_factor)\n",
    "        ## If shiny was specified: use policy that uses shiny policy to approach shiny objects\n",
    "        ## sequentially\n",
    "        ##else:\n",
    "        ##    new_walk = self.walk_shiny(new_walk, walk_length, repeat_bias_factor)\n",
    "        # Clean up walk a bit by only keep essential location dictionary entries\n",
    "        for step in new_walk[:-1]:\n",
    "            step[0] = {'id': step[0]['id'], 'shiny': step[0]['shiny']}\n",
    "        # Append new walk to list of walks\n",
    "        walks.append(new_walk)   \n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ace6a4-2897-4a1b-89f3-15cb2e86ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And make a single walk for each environment, where walk lengths can be any between the min and max\n",
    "# length to de-sychronise world switches.\n",
    "\n",
    "# Minimum length of a walk on one environment. Walk lengths are sampled uniformly from a window\n",
    "# that shifts down until its lower limit is walk_it_min at the end of training\n",
    "# params['walk_it_min'] = 25\n",
    "# Maximum length of a walk on one environment. Walk lengths are sampled uniformly from a window\n",
    "# that starts with its upper limit at walk_it_max in the beginning of training, then shifts down\n",
    "# params['walk_it_max'] = 300\n",
    "params = {\n",
    "    # Number of steps to roll out before backpropagation through time\n",
    "    'n_rollout': 20,\n",
    "    # Minimum length of a walk on one environment. Walk lengths are sampled uniformly from a window\n",
    "    # that shifts down until its lower limit is walk_it_min at the end of training\n",
    "    'walk_it_min': 25,\n",
    "    # Maximum length of a walk on one environment. Walk lengths are sampled uniformly from a window\n",
    "    # that starts with its upper limit at walk_it_max in the beginning of training, then shifts down\n",
    "    'walk_it_max': 300,\n",
    "}\n",
    "walks = [\n",
    "    env.generate_walks(\n",
    "        env,\n",
    "        params['n_rollout']*np.random.randint(params['walk_it_min'], params['walk_it_max']),\n",
    "        1,\n",
    "    )[0] for env in environments\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc91c5-78ed-4413-bf52-17c70b27d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward-pass this walk through the network\n",
    "# forward = tem(chunk, prev_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1413f-0c80-4975-86bc-93aba6a8206a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdb1fc-746b-412c-bf38-a5fb8277065b",
   "metadata": {},
   "source": [
    "The TEM model is based on the architecture described in the paper, where there are representations for:\n",
    "\n",
    "* Abstract location (`g`) - corresponding to grid cells in medial entorhinal cortex\n",
    "* Grounded location (`p`) - corresponding to place cells in hippocampus\n",
    "* Sensory observations (`x`) - corresponding to lateral entorhinal cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8adb218f-4586-423b-8506-fd0ae458753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters():\n",
    "    params = {}\n",
    "    # -- Model parameters   \n",
    "    # Decide whether to use seperate grid modules that recieve shiny information for object vector cells.\n",
    "    # To disable OVC, set this False, and set n_ovc to [0 for _ in range(len(params['n_g_subsampled']))].\n",
    "    params['separate_ovc'] = False\n",
    "\n",
    "    # ---- Neuron and module parameters\n",
    "    # Neurons for subsampled entorhinal abstract location f_g(g) for each frequency module\n",
    "    params['n_g_subsampled'] = [10, 10, 8, 6, 6]\n",
    "    # Neurons for object vector cells. Neurons will get new modules if object vector cell modules\n",
    "    # are separated; otherwise, they are added to existing abstract location modules.\n",
    "    # a) No additional modules, no additional object vector neurons (e.g. when not using shiny\n",
    "    #    environments): [0 for _ in range(len(params['n_g_subsampled']))], and separate_ovc set to False\n",
    "    # b) No additional modules, but n additional object vector neurons in each grid module:\n",
    "    #    [n for _ in range(len(params['n_g_subsampled']))], and separate_ovc set to False\n",
    "    # c) Additional separate object vector modules, with n, m neurons: [n, m], and separate_ovc set to\n",
    "    #    True\n",
    "    params['n_ovc'] = [0 for _ in range(len(params['n_g_subsampled']))]\n",
    "    # Total number of modules\n",
    "    params['n_f'] = len(params['n_g_subsampled'])\n",
    "\n",
    "    # Number of hierarchical frequency modules for object vector cells\n",
    "    params['n_f_ovc'] = len(params['n_ovc']) if params['separate_ovc'] else 0\n",
    "\n",
    "    # Initial frequencies of each module. For ease of interpretation (higher number = higher frequency)\n",
    "    # this is 1 - the frequency as James uses it\n",
    "    params['f_initial'] = [0.99, 0.3, 0.09, 0.03, 0.01]\n",
    "    # Add frequencies of object vector cell modules, if object vector cells get separate modules\n",
    "    params['f_initial'] = params['f_initial'] + params['f_initial'][0:params['n_f_ovc']]\n",
    "    return params\n",
    "\n",
    "# Initalise hyperparameters for model\n",
    "params = parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "284c72d7-9c33-4be5-ac6d-3a96a31594ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'separate_ovc': False,\n",
       " 'n_g_subsampled': [10, 10, 8, 6, 6],\n",
       " 'n_ovc': [0, 0, 0, 0, 0],\n",
       " 'n_f': 5,\n",
       " 'n_f_ovc': 0,\n",
       " 'f_initial': [0.99, 0.3, 0.09, 0.03, 0.01]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0258fe30-6016-4a4d-8d5a-304b3a43e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters\n",
    "np.save(os.path.join(save_path, 'params'), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4424e70f-9448-4b26-9df3-7def8f566c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9b3f4c4-e34f-41bb-b8ce-6e0af36d4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale factor in Laplacian transform for each frequency module. High frequency comes first, low frequency comes last. Learn inverse sigmoid instead of scale factor directly, so domain of alpha is -inf, inf\n",
    "alpha = torch.nn.ParameterList(\n",
    "    [\n",
    "        torch.nn.Parameter(\n",
    "            torch.tensor(\n",
    "                np.log(hyper['f_initial'][f] / (1 - hyper['f_initial'][f])),\n",
    "                dtype=torch.float,\n",
    "            )\n",
    "        ) for f in range(hyper['n_f'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ab4cf71-ae73-42c9-85e1-92f558de2ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.float32 of size ]\n",
       "    (1): Parameter containing: [torch.float32 of size ]\n",
       "    (2): Parameter containing: [torch.float32 of size ]\n",
       "    (3): Parameter containing: [torch.float32 of size ]\n",
       "    (4): Parameter containing: [torch.float32 of size ]\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d3306-d7a4-4160-9fc6-5de0acc438f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
