{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7ac8a5-35b8-49c6-8617-3ae52b1221e8",
   "metadata": {},
   "source": [
    "Many image processing libraries and frameworks actually implement cross-correlation when they say \"convolution\".\n",
    "This is because for symmetric filters (like Gaussian filters), convolution and cross-correlation give identical results.\n",
    "For asymmetric filters, you might need to be careful about which operation you're actually using.\n",
    "\n",
    "When you do true convolution with an impulse:\n",
    "\n",
    "1. You first flip the filter (both horizontally and vertically)\n",
    "1. Then slide it over the impulse\n",
    "1. Because of the mathematical properties of convolution with an impulse, the result you get is the original filter (not the flipped version)\n",
    "\n",
    "\n",
    "If you did cross-correlation with an impulse:\n",
    "\n",
    "1. You'd slide the filter directly (no flipping)\n",
    "1. The result would be the flipped version of the filter\n",
    "\n",
    "Cross-correlation is when you directly slide the filter over the image, multiplying and summing. The operation looks like this:\n",
    "$$\n",
    "(f \\cdot g)[n] = \\sum f[m] \\times g[m+n]\n",
    "$$\n",
    "\n",
    "Convolution is similar but involves flipping the filter (both horizontally and vertically) first:\n",
    "$$\n",
    "(f \\star g)[n] = \\sum f[m] \\times g[n-m]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41cee686-e192-4eaa-9d81-9803fe5b8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9ebc42-8713-47a5-9f6d-cdbc5b852c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_identity = np.identity(3)\n",
    "_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b87b51-39a0-4577-9961-a6953283d66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]]),\n",
       " array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.]]),\n",
       " array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flip along the vertical axis (axis=0).\n",
    "# axis=1 is a flip along the horizontal axis.\n",
    "np.flip(_identity), np.flip(_identity, axis=0), np.flip(_identity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ec6120-8d89-40b5-bb13-efc5a8d38748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_reverse_identity = np.flip(_identity, axis=0)\n",
    "_reverse_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595a08f6-8de0-40d8-afa4-8f67281565d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The transpose of the reverse identity is itself.\n",
    "_reverse_identity.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c5f658-9c4a-4185-887b-2528e25df38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The transpose of the identity is itself.\n",
    "_identity.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb79a55-396e-4373-b1e1-a79e105eaa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]]),\n",
       " (3, 3),\n",
       " dtype('int64'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_filter = np.array(\n",
    "    [\n",
    "        [0, 1, 2],\n",
    "        [3, 4, 5],\n",
    "        [6, 7, 8],\n",
    "    ]\n",
    ")\n",
    "img_filter, img_filter.shape, img_filter.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164bf0e3-959b-483d-bf3f-41d2b0d4ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 7., 8.],\n",
       "       [3., 4., 5.],\n",
       "       [0., 1., 2.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vertical flip.\n",
    "np.matmul(_reverse_identity, img_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac82635-0a52-4128-9d3e-466fb9da856f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 7., 8.],\n",
       "       [3., 4., 5.],\n",
       "       [0., 1., 2.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vertical flip.\n",
    "# Same as above but using the more convenient notation.\n",
    "_reverse_identity.T @ img_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bfa78c1-e03a-4444-9b36-fc52ccb77f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1., 0.],\n",
       "       [5., 4., 3.],\n",
       "       [8., 7., 6.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Horizontal flip!!!\n",
    "img_filter @ _reverse_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879f34f9-b75c-412e-a589-19d04b77c37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8., 7., 6.],\n",
       "       [5., 4., 3.],\n",
       "       [2., 1., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double flip!!!\n",
    "_reverse_identity.T @ img_filter @ _reverse_identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6507cfe-b8fa-4e94-a0e3-824480387133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_impulse_img = scipy.signal.unit_impulse((3, 3), 'mid')\n",
    "_impulse_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c32001b-1bbe-486c-a208-b620728cb16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8., 7., 6.],\n",
       "       [5., 4., 3.],\n",
       "       [2., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_convolve = _reverse_identity.T @ img_filter @ _reverse_identity\n",
    "_convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "813de51f-e2b4-4187-b307-51411568033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 2., 0.],\n",
       "       [0., 3., 4., 5., 0.],\n",
       "       [0., 6., 7., 8., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The convention in image processing/computer vision is typically:\n",
    "# First argument is considered the \"image\" or \"signal\".\n",
    "# Second argument is considered the \"kernel\" or \"filter\".\n",
    "# First img_filter gets double flipped and then it does correlation.\n",
    "scipy.signal.convolve(_impulse_img, img_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4719fbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 2., 0.],\n",
       "       [0., 3., 4., 5., 0.],\n",
       "       [0., 6., 7., 8., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See!\n",
    "# Here we manually did the double flipping of the filter before doing the correlation step\n",
    "# ourselves.\n",
    "scipy.signal.correlate(_impulse_img, _convolve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a95e527-44dc-4781-a742-c2bf84b8f4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 8., 7., 6., 0.],\n",
       "       [0., 5., 4., 3., 0.],\n",
       "       [0., 2., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And just for kicks...\n",
    "scipy.signal.convolve(_impulse_img, _convolve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb3558-b24a-4df1-adf0-a79729c7ab01",
   "metadata": {},
   "source": [
    "## Manual Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff410f78-9176-417f-949d-aac43c8f70d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  9., 11.],\n",
       "       [15., 17., 19.],\n",
       "       [23., 25., 27.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "4x4 input:        Possible 2x2 kernel positions:\n",
    "[ ][ ][ ][ ]      [K][K][ ][ ]     [ ][K][K][ ]     [ ][ ][K][K]\n",
    "[ ][ ][ ][ ]      [K][K][ ][ ]     [ ][K][K][ ]     [ ][ ][K][K]\n",
    "[ ][ ][ ][ ]      [ ][ ][ ][ ]     [ ][ ][ ][ ]     [ ][ ][ ][ ]\n",
    "[ ][ ][ ][ ]      [ ][ ][ ][ ]     [ ][ ][ ][ ]     [ ][ ][ ][ ]\n",
    "\n",
    "                  [ ][ ][ ][ ]      [ ][ ][ ][ ]     [ ][ ][ ][ ]\n",
    "                  [K][K][ ][ ]      [ ][K][K][ ]     [ ][ ][K][K]\n",
    "                  [K][K][ ][ ]      [ ][K][K][ ]     [ ][ ][K][K]\n",
    "                  [ ][ ][ ][ ]      [ ][ ][ ][ ]     [ ][ ][ ][ ]\n",
    "\n",
    "                  [ ][ ][ ][ ]      [ ][ ][ ][ ]     [ ][ ][ ][ ]\n",
    "                  [ ][ ][ ][ ]      [ ][ ][ ][ ]     [ ][ ][ ][ ]\n",
    "                  [K][K][ ][ ]      [ ][K][K][ ]     [ ][ ][K][K]\n",
    "                  [K][K][ ][ ]      [ ][K][K][ ]     [ ][ ][K][K]\n",
    "\"\"\"\n",
    "# Manual correlation.\n",
    "# Create a simple 4x4 \"image\".\n",
    "image = np.array([\n",
    "    [1,  2,  3,  4],\n",
    "    [5,  6,  7,  8],\n",
    "    [9,  10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "# Create a 2x2 kernel.\n",
    "kernel = np.identity(2)\n",
    "\n",
    "# Output will be 3x3 due to kernel size.\n",
    "# output_size = input_size - kernel_size + 1 -> 4 - 2 + 1 = 3.\n",
    "result = np.zeros((3, 3))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        # For each position, multiply kernel with corresponding image region.\n",
    "        # This (the following op, not the op + the np.sum()) is the Hadamard product,\n",
    "        # element-wise multiplication, not matrix multiplication.\n",
    "        region = image[i:i+2, j:j+2]\n",
    "        value = np.sum(region * kernel)\n",
    "        result[i, j] = value\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06e78b0b-f941-4c10-9eb3-18aeaa39d052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0.],\n",
       "        [0., 6.]]),\n",
       " array([[1., 2.],\n",
       "        [5., 6.]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hadamard product:\n",
    "[[1, 2],     [[1, 0],     [[1*1, 2*0],     [[1, 0],\n",
    " [5, 6]]  *   [0, 1]]  =   [5*0, 6*1]]  =  [0, 6]]\n",
    "\"\"\"\n",
    "# First is Hadamard product.\n",
    "# Second is the matmul.\n",
    "image[0:2, 0:2] * kernel, image[0:2, 0:2] @ kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45813163-94a2-441a-988d-b72e2261b298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 7.,  9., 11.],\n",
       "        [15., 17., 19.],\n",
       "        [23., 25., 27.]]),\n",
       " array([[ 1.,  2.,  3.,  4.,  0.],\n",
       "        [ 5.,  7.,  9., 11.,  4.],\n",
       "        [ 9., 15., 17., 19.,  8.],\n",
       "        [13., 23., 25., 27., 12.],\n",
       "        [ 0., 13., 14., 15., 16.]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default mode will take into account the boundary conditions.\n",
    "scipy.signal.correlate(image, kernel, mode='valid'), scipy.signal.correlate(image, kernel, mode='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a2058-8eb5-4601-8d3b-7a1a3089f435",
   "metadata": {},
   "source": [
    "## Complex Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b188cc5-8e20-4e5b-be37-0828b74dc326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.+2.j, 3.-1.j],\n",
       "        [0.+3.j, 4.+6.j]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_matrix = np.matrix(\n",
    "    [\n",
    "        [1+2j, 3-1j],\n",
    "        [0+3j, 4+6j],\n",
    "    ],\n",
    ")\n",
    "_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f48f364-0086-488c-953e-9c17dffa513a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.+2.j, 0.+3.j],\n",
       "        [3.-1.j, 4.+6.j]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d35b3ee-5f91-43bd-80c6-20a925fe98c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.-2.j, 0.-3.j],\n",
       "        [3.+1.j, 4.-6.j]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_matrix.T.conj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaf1c008-d713-46fb-9d00-520d2546ad72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.-2.j, 0.-3.j],\n",
       "        [3.+1.j, 4.-6.j]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_matrix.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd53956-b3f4-4f97-96ae-33331444cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_impulse_img = scipy.signal.unit_impulse((2, 2), 'mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d418b44-3522-4419-b303-fd98a5327c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.+0.j, 0.+0.j, 0.+0.j],\n",
       "       [0.+0.j, 1.+2.j, 3.-1.j],\n",
       "       [0.+0.j, 0.+3.j, 4.+6.j]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.signal.convolve(_impulse_img, _matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba71639d-8393-40e0-84aa-8964648df004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.+0.j, 0.+0.j, 0.+0.j],\n",
       "       [0.+0.j, 4.-6.j, 0.-3.j],\n",
       "       [0.+0.j, 3.+1.j, 1.-2.j]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.signal.correlate(_impulse_img, _matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcddc4d1-23ad-4a8c-a610-24e9b439eff0",
   "metadata": {},
   "source": [
    "# Normalized Cross-Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99509e60-5c6b-44ef-8ab5-bf7f2066d17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 13, 18, 23, 28, 33, 38])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_signal = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "_template = np.array([2, 3])\n",
    "\n",
    "\"\"\"\n",
    "Position 0: (1×2 + 2×3) = 8     # [1,2] × [2,3]\n",
    "Position 1: (2×2 + 3×3) = 13    # [2,3] × [2,3]  <- This is where template actually matches!\n",
    "Position 2: (3×2 + 4×3) = 18    # [3,4] × [2,3]\n",
    "Position 3: (4×2 + 5×3) = 23    # [4,5] × [2,3]\n",
    "...and so on\n",
    "\"\"\"\n",
    "correlation = scipy.signal.correlate(_signal, _template, mode='valid')\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa5d2636-f891-407b-8538-c359d112c1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(6), np.int64(7))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(correlation), _signal[np.argmax(correlation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "448b05ab-c5d1-4fe9-852f-9b37ae629e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(_template, _template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea452b37-29e3-42d1-8ca5-a51b6b6e1a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]),)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to find a match when the correlation is not normalized then we ought to look for it\n",
    "# based on what it should look like.\n",
    "np.where(np.dot(_template, _template) == correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b18630d2-3c82-4c23-bac8-7ca5b9854cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0,  1,  0,  0, -1, -1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_signal = np.array([1, 1, 0, 1, 0, 0, -1, -1, 1])\n",
    "_template = np.array([0, 1, 0])\n",
    "\n",
    "correlation = scipy.signal.correlate(_signal, _template, mode='valid')\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4a6563b-2515-4b38-8a4d-99c050eda9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99227788, 1.        , 0.99846035, 0.99624059, 0.99430915,\n",
       "       0.99273378, 0.9914543 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_signal = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "_template = np.array([2, 3])\n",
    "\n",
    "corr = scipy.signal.correlate(_signal, _template, mode='valid')\n",
    "\n",
    "\"\"\"\n",
    "When normalizing correlation, you want to normalize each window independently against the template.\n",
    "The proper way is your first example:\n",
    "\n",
    "For each window of the signal (same length as template):\n",
    "\n",
    "Compute norm of that window\n",
    "Compute norm of template\n",
    "Divide correlation value by (window_norm * template_norm)\n",
    "\n",
    "when sliding the template across the signal, each position needs its own normalization based\n",
    "on the values in that specific window.\n",
    "\"\"\"\n",
    "template_norm = np.linalg.norm(_template) # Same as np.sqrt( np.sum(np.square(_template)))\n",
    "windows = np.lib.stride_tricks.sliding_window_view(_signal, _template.size)\n",
    "window_norms = np.linalg.norm(windows, axis=1) # Same as np.sqrt(np.sum(np.square(windows), axis=1))\n",
    "normalized_corr = corr / (window_norms * template_norm)\n",
    "normalized_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfda505e-09f5-4806-9b8f-9c5af99321ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 3],\n",
       "       [3, 4],\n",
       "       [4, 5],\n",
       "       [5, 6],\n",
       "       [6, 7],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we saw above, the cross correlation is done by sliding the filter over the signal.\n",
    "# Turns out there is a function for that!\n",
    "windows = np.lib.stride_tricks.sliding_window_view(_signal, 2)\n",
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27058805-125f-4f39-a9ab-f55477b14f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  4],\n",
       "        [ 4,  9],\n",
       "        [ 9, 16],\n",
       "        [16, 25],\n",
       "        [25, 36],\n",
       "        [36, 49],\n",
       "        [49, 64]]),\n",
       " array([  5,  13,  25,  41,  61,  85, 113]),\n",
       " array([ 2.23606798,  3.60555128,  5.        ,  6.40312424,  7.81024968,\n",
       "         9.21954446, 10.63014581]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(windows), np.sum(np.square(windows), axis=1), np.sqrt( np.sum(np.square(windows), axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9182478d-3080-4f8d-85f3-af09984db304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.23606798,  3.60555128,  5.        ,  6.40312424,  7.81024968,\n",
       "         9.21954446, 10.63014581]),\n",
       " array([11.83215957, 14.24780685]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want the norm over axis=1.\n",
    "# When you pass axis=1, you are telling np.linalg.norm to compute the norm along the second dimension (columns)\n",
    "# for each row.\n",
    "# Thus, passing axis=0 will compute the norm along the rows for each column.\n",
    "np.linalg.norm(windows, axis=1), np.linalg.norm(windows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b4d18cb-54e7-4069-a42c-b17439389f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3.605551275463989), np.float64(3.605551275463989))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_norm = np.sqrt( np.sum(np.square(_template)))\n",
    "template_norm, np.linalg.norm(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "65faeef9-ac96-4b50-aac2-5736245cf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(signal, signal_filter):\n",
    "    \"\"\"\n",
    "    When normalizing correlation, you want to normalize each window independently against the template.\n",
    "    The proper way is your first example:\n",
    "    \n",
    "    For each window of the signal (same length as template):\n",
    "    \n",
    "    1. Compute norm of that window\n",
    "    2. Compute norm of template\n",
    "    3. Divide correlation value by (window_norm * template_norm)\n",
    "    \n",
    "    when sliding the template across the signal, each position needs its own normalization based\n",
    "    on the values in that specific window.\n",
    "    \"\"\"\n",
    "    correlation = scipy.signal.correlate(signal, signal_filter, mode='valid')\n",
    "\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(signal, signal_filter.size)\n",
    "    window_norms = np.linalg.norm(windows, axis=1) # Same as np.sqrt(np.sum(np.square(windows), axis=1))\n",
    "\n",
    "    filter_norm = np.linalg.norm(signal_filter) # Same as np.sqrt( np.sum(np.square(_template)))\n",
    "    \n",
    "    return correlation / (window_norms * filter_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8b4b979d-af60-4ae6-b1b4-770929608059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        , -0.5       ,  0.5       ,  0.81649658,  1.        ,\n",
       "         0.5       , -0.5       , -1.        , -0.5       ,  0.70710678,\n",
       "         0.70710678,  0.        , -0.5       ,  0.        ,  1.        ,\n",
       "         0.5       ,  0.5       ,  1.        ]),\n",
       " (18,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = np.array([1, -1, 0, 1, 1, 1, 0, -1, -1, -1, 1, 0, 0, -1, 1, 1, 0, 1, 1, 0])\n",
    "signal_filter = np.array([1, 1, 0])\n",
    "\n",
    "norm_corr = normalized_cross_correlation(signal, signal_filter)\n",
    "norm_corr, norm_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "002a9679-28db-46b5-84f5-c4cb34739710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = int(np.argmax(norm_corr))\n",
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d678f913-1ecd-433c-8ed2-1ecdb52ba274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal[max_idx:max_idx+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "535c27db-29b8-4e7e-8674-5d31c1610817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "034f5f8f-1ff5-43db-a236-c351c787b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.where(np.isclose(norm_corr, norm_corr[max_idx], rtol=1e-3))\n",
    "matches = matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9ac3f6ae-7447-4020-b17e-6ded2837985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  4 : [1 1 0]\n",
      "idx: 14 : [1 1 0]\n",
      "idx: 17 : [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "for idx in matches:\n",
    "    print(f'idx: {idx:2d} : {signal[idx:idx+3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f0fcd89-91f7-4bf2-b882-15f908e619d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation_full(signal, signal_filter):\n",
    "    correlation = scipy.signal.correlate(signal, signal_filter, mode='full')\n",
    "    \n",
    "    # For full correlation, we need to pad the signal to handle edge cases.\n",
    "    pad_width = signal_filter.size - 1\n",
    "    padded_signal = np.pad(signal, pad_width)\n",
    "    \n",
    "    # Get windows for the entire padded signal.\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(padded_signal, signal_filter.size)\n",
    "    \n",
    "    # Compute norms for all windows.\n",
    "    window_norms = np.linalg.norm(windows, axis=1)\n",
    "    \n",
    "    # Compute template norm.\n",
    "    filter_norm = np.linalg.norm(signal_filter)\n",
    "    \n",
    "    # Avoid division by zero.\n",
    "    eps = np.finfo(float).eps\n",
    "    denominator = window_norms * filter_norm\n",
    "    denominator = np.where(denominator > eps, denominator, eps)\n",
    "    \n",
    "    return correlation / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92d6dea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        , -0.70710678, -0.70710678,  0.        ,  0.5       ,\n",
       "         0.81649658,  1.        ,  0.5       , -0.5       , -1.        ,\n",
       "        -0.5       ,  0.70710678,  0.70710678,  0.        , -0.70710678,\n",
       "        -0.70710678]),\n",
       " (16,))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal = np.array([-1, 0, 0, 1, 1, 1, 0, -1, -1, 0, 1, 0, 0, -1])\n",
    "signal_filter = np.array([1, 1, 0])\n",
    "\n",
    "norm_corr = normalized_cross_correlation_full(signal, signal_filter)\n",
    "norm_corr, norm_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "beeb29d2-3b02-45b8-b67f-762f1e309ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 16)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.size, norm_corr.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9db11285-ae42-4f45-b2b7-03248fb5e938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  6 : [ 0 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "max_idx = int(np.argmax(norm_corr))\n",
    "matches = np.where(np.isclose(norm_corr, norm_corr[max_idx], rtol=1e-3))\n",
    "matches = matches[0]\n",
    "for idx in matches:\n",
    "    print(f'idx: {idx:2d} : {signal[idx:idx+3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733d6e0-0091-40f3-9c57-0ac8a69f5ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
